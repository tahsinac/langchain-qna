{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain LLM Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "J.K. Rowling\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY,temperature=0.6)\n",
    "text=\"Who is the author of the book Harry Potter?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness is a sour taste\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN, repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0.4,\"max_length\":264})\n",
    "output=llm_huggingface.predict(\"Write a haiku about sadness\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tears fall like raindrops\n",
      "Heavy heart weighs like boulders\n",
      "Sadness consumes me\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text=\"Write a haiku about sadness\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template And LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a haiku about clocks'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['subject'], template=\"Write a haiku about {subject}\")\n",
    "\n",
    "prompt_template.format(subject=\"clocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\langchain-qna\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Crispy chickpea balls\n",
      "Golden brown and full of spice\n",
      "Satisfy my soul \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"falafels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template=PromptTemplate(input_variables=['area'], template=\"Give me the name of one concept used in {area}\")\n",
    "question_chain=LLMChain(llm=llm,prompt=question_template)\n",
    "eli11_template=PromptTemplate(input_variables=['topic'], template=\"Explain {topic} to an eleven year old\")\n",
    "eli11_chain=LLMChain(llm=llm,prompt=eli11_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Neural networks are like a big group of friends who work together to solve a problem. Each friend has a different job, and they all share information with each other to figure out the best solution. Just like how we ask our friends for help with homework or a game, neural networks ask their friends (or neurons) for help to solve a problem. And the more they work together, the better they get at solving the problem! \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[question_chain, eli11_chain])\n",
    "print(chain.run(\"Machine learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Imagine you are blowing up a balloon and then letting it go. As you let go, the air rushes out of the balloon quickly, causing the balloon to fly around the room. This is because of Bernoulli's principle! The air inside the balloon is moving very quickly, so its pressure decreases. This creates a difference in air pressure between the inside and outside of the balloon, causing it to move. This same principle is used in airplanes to create lift and in jet engines to produce thrust. It's like a superpower that helps airplanes fly and move through the air!\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"Aviation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keys in Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template=PromptTemplate(input_variables=['area'], template=\"Give me the name of one concept used in {area}\")\n",
    "question_chain=LLMChain(llm=llm,prompt=question_template, output_key='concept')\n",
    "eli11_template=PromptTemplate(input_variables=['concept'], template=\"Explain {concept} to an eleven year old\")\n",
    "eli11_chain=LLMChain(llm=llm,prompt=eli11_template, output_key='explanation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain=SequentialChain(chains=[question_chain, eli11_chain], input_variables=['area'], output_variables=['concept', 'explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': 'Aviation',\n",
       " 'concept': '\\n\\nAerodynamics\\n',\n",
       " 'explanation': \"\\n\\nAerodynamics is the study of how air moves around objects, like airplanes, cars, and even birds. It helps us understand how to design things that can move through the air efficiently and safely. By using aerodynamics, we can make things that can fly faster, go further, and use less fuel. It's like figuring out the best way to ride a bike to make it go faster and easier!\"}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'area':\"Aviation\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatmodels With ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\langchain-qna\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=OPENAI_API_KEY,temperature=0.3,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"A quantum computer is a super-duper powerful computer that uses something called quantum mechanics to do really complex calculations. Regular computers use bits to store and process information, which are like tiny switches that can be either on or off, represented by 0s and 1s. But quantum computers use something called qubits, which can be both 0 and 1 at the same time! This is because of a weird property called superposition.\\n\\nBecause of this superposition thing, quantum computers can do a lot of calculations all at once, which makes them really fast and powerful. They can solve problems that would take regular computers a really long time, like figuring out the best route for a delivery truck or finding new medicines. It's like having a super brain that can think about a million things at once! But quantum computers are still being developed and are not yet as common as regular computers.\")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"You are an AI assitant that gives explanations in such a way that eleven year olds can understand them.\"),\n",
    "HumanMessage(content=\"What is a quantum computer?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the user gives any word, you should generate 5 synonyms in a comma separated list.\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generous', ' considerate', ' compassionate', ' benevolent', ' thoughtful']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"kind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
